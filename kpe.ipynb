{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from string import punctuation\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "def main():\n",
    "    rleaves = pd.read_csv('rleaves.csv', encoding='utf-8')\n",
    "    rleaves = rleaves['raw']\n",
    "    rleaves = rleaves.apply(cleanup)\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"mrm8488/t5-base-finetuned-emotion\")\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(\"mrm8488/t5-base-finetuned-emotion\")\n",
    "    \n",
    "    emotions = rleaves.apply(get_emotion)\n",
    "    emotions = emotions.str.replace('<pad> |</s>', '')\n",
    "    \n",
    "    rleaves.name = 'post'\n",
    "    emotions.name = 'emotion'\n",
    "    rleaves_emotion = pd.concat([rleaves, emotions], axis=1)\n",
    "    rleaves_emotion.to_csv('rleaves_emotion.csv', index=False)\n",
    "\n",
    "def cleanup(text):\n",
    "    text = text.lower() # lowers the corpus\n",
    "    text = re.sub('http\\S+', ' ', str(text)) # removes any url\n",
    "    text = re.sub('n\\'t\\s', ' not ', str(text)) # change apostrophe\n",
    "    text = re.sub('-(?<!\\d)', ' ', str(text)) # removing hyphens from numbers\n",
    "    my_punctuation = punctuation.replace(\".\", \"\") # removes all punctuation except period\n",
    "    text = text.translate(str.maketrans('', '', my_punctuation))\n",
    "    text = re.sub('’|“|”|\\.{2,}', '', str(text))\n",
    "    text = re.sub('x200b', ' ', str(text)) # removing zero-width space characters\n",
    "    return ' '.join([token for token in text.split()]) # removes trailing whitespaces\n",
    "\n",
    "def get_emotion(text):\n",
    "    input_ids = tokenizer.encode(text, return_tensors='pt')\n",
    "    output = model.generate(input_ids=input_ids)\n",
    "    dec = [tokenizer.decode(ids) for ids in output]\n",
    "    label = dec[0]\n",
    "    return label\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating for features \n",
    "actions = pd.DataFrame(rleaves['raw'])\n",
    "actions['num'] = np.where(actions['raw'].str.contains('\\d+'), True, False) # looks for all numbers\n",
    "actions['period'] = np.where(actions['raw'].str.contains('\\s*days* |\\s*months* |\\s*weeks* |\\s*ye?a?rs* '), True, False) # looks for time\n",
    "actions = actions.loc[(actions['num'] == True) & (actions['period'] == True)] # filter only those rows\n",
    "actions['day'] = np.where(actions['raw'].str.contains('\\d+\\s*day[s\\s]|\\s*day\\s*\\d+'), True, False) # indicates whether number is day or not\n",
    "actions['week'] = np.where(actions['raw'].str.contains('\\d+\\s*week[s\\s]|\\s*week\\s*\\d+'), True, False) # indicates whether number is week or not\n",
    "actions['month'] = np.where(actions['raw'].str.contains('\\d+\\s*month[s\\s]|\\s*month\\s*\\d+'), True, False) # indicates whether number is month or not\n",
    "actions['year'] = np.where(actions['raw'].str.contains('\\d+\\s*ye?a?r[s\\s]*'), True, False) # indicates whether number is year or not\n",
    "actions['nums'] = actions['raw'].str.findall('\\d+') # strips all the number\n",
    "actions['nums'] = [[int(n) for n in sub] for sub in actions['nums']] # convert all numbers to int\n",
    "actions['nums'] = actions['nums'].apply(lambda x: min(x)) # keep only the smallest numbers\n",
    "actions = actions.loc[(actions['nums'] > 0) & (actions['nums'] < 800)] # remove outliers\n",
    "actions[['day', 'week', 'month', 'year']] = actions[['day', 'week', 'month', 'year']].cumsum(axis=1).cumsum(axis=1) == 1 # keeping only first trues\n",
    "actions.drop(columns=['num', 'period'], inplace=True) # drop columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function to find ****\n",
    "def find_actions(text):\n",
    "    matcher = Matcher(sp.vocab)\n",
    "    pattern = [{'DEP': 'amod'},\n",
    "                {'POS': 'NOUN'}]\n",
    "    matcher.add(\"find_actions\", None, pattern)\n",
    "    doc = sp(''.join(text))\n",
    "    matches = matcher(doc)\n",
    "    acts = []\n",
    "    for match_id, start, end in matches:\n",
    "        span = doc[start:end]\n",
    "        acts.append(span.text) \n",
    "    return acts\n",
    "\n",
    "# apply function\n",
    "rleaves['actions'] = rleaves['raw'].apply(find_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tough sense',\n",
       " 'clear mind',\n",
       " 'easy place',\n",
       " 'pass thinking',\n",
       " 'crazy tangent',\n",
       " 'hard mind',\n",
       " 'crazy tangent',\n",
       " 'meditate experience',\n",
       " 'crazy tangent',\n",
       " 'long time',\n",
       " 'ambitious starting',\n",
       " 'comfortable position',\n",
       " 'black room',\n",
       " 'mental note',\n",
       " 'obsessed work',\n",
       " 'second week',\n",
       " 'actual sensation',\n",
       " 'moving nose',\n",
       " 'repetitive minute',\n",
       " 'repetitive idea',\n",
       " 'chatty thought',\n",
       " 'peaceful repetition',\n",
       " 'repetitive place',\n",
       " 'frustrated time',\n",
       " 'peaceful repetition',\n",
       " 'peaceful repetition',\n",
       " 'inner thought',\n",
       " 'few time',\n",
       " 'inner dialog',\n",
       " 'automatic influence']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rleaves['actions'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = pd.DataFrame(rleaves['actions'][1], columns=['actions'])\n",
    "b['polarity'] = b['actions'].apply(lambda x: TextBlob(x).polarity)\n",
    "b['subjective'] = b['actions'].apply(lambda x: TextBlob(x).subjectivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "805"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rleaves['author'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from streamlit_disqus import st_disqus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_disqus(\"streamlit-disqus-demo\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
